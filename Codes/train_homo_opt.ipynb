{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/thomas/RAFT')\n",
    "sys.path.append('/home/thomas/RAFT/core')\n",
    "sys.path.append('/home/thomas/RAFT/models')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import cv2\n",
    "from PIL import Image as IMG\n",
    "import time\n",
    "import random\n",
    "import torch.optim as optim\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import math\n",
    "import rospy\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from message_filters import Subscriber, ApproximateTimeSynchronizer\n",
    "import torch.nn.init as init\n",
    "from copy import deepcopy\n",
    "import torchvision.models as models\n",
    "import itertools\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_specular_highlight(img, intensity=1.5, radius=20):\n",
    "    \"\"\"Adds a bright circular spot to simulate reflection on glass/shiny surfaces.\"\"\"\n",
    "    h, w, _ = img.shape\n",
    "    cx, cy = random.randint(0, w-1), random.randint(0, h-1)\n",
    "    mask = np.zeros((h, w), dtype=np.float32)\n",
    "    cv2.circle(mask, (cx, cy), radius, 1, -1)\n",
    "    mask = cv2.GaussianBlur(mask, (radius//2*2+1, radius//2*2+1), 0)\n",
    "    highlight = (img * (1 + intensity * mask[..., None])).clip(0, 1)\n",
    "    return highlight\n",
    "\n",
    "def add_lens_flare(img, num_streaks=3):\n",
    "    \"\"\"Adds simple lens flare streaks.\"\"\"\n",
    "    h, w, _ = img.shape\n",
    "    flare = img.copy()\n",
    "    cx, cy = random.randint(0, w-1), random.randint(0, h-1)\n",
    "    for _ in range(num_streaks):\n",
    "        dx, dy = random.choice([(-1,0),(1,0),(0,-1),(0,1)])\n",
    "        length = random.randint(50, min(h,w)//2)\n",
    "        overlay = np.zeros_like(img)\n",
    "        for i in range(length):\n",
    "            x, y = cx + dx*i, cy + dy*i\n",
    "            if 0 <= x < w and 0 <= y < h:\n",
    "                overlay[y, x] = [1, 1, 1]  # white flare\n",
    "        flare = np.clip(flare + cv2.GaussianBlur(overlay, (15,15), 0)*0.3, 0, 1)\n",
    "    return flare\n",
    "\n",
    "def add_tint(img, color=(0.8, 1.0, 1.2)):\n",
    "    \"\"\"Applies a global tint (RGB multiplier).\"\"\"\n",
    "    tinted = (img * np.array(color)[None, None, :]).clip(0, 1)\n",
    "    return tinted\n",
    "\n",
    "def pt_trans(img, ph_trans=False, homo=False):\n",
    "    \"\"\"\n",
    "    img: numpy array of shape (H, W), grayscale image\n",
    "    ph_trans: whether to apply photometric transforms\n",
    "    \"\"\"\n",
    "    if ph_trans:\n",
    "        if img.ndim == 2:\n",
    "            img = np.stack([img]*3, axis=-1)\n",
    "        img = torch.tensor(img).permute(2,0,1) / 255.0\n",
    "        img = T.ToPILImage()(img)\n",
    "        photometric_transforms = T.Compose([\n",
    "            T.ColorJitter(\n",
    "                brightness=0.5,\n",
    "                contrast=0.5,\n",
    "                saturation=0.5,\n",
    "                hue=0.1\n",
    "            ),\n",
    "            T.RandomApply([T.GaussianBlur(3)], p=0.2),\n",
    "        ])\n",
    "        img = photometric_transforms(img)\n",
    "        img = T.ToTensor()(img).permute(1,2,0).numpy()\n",
    "        if random.random() < 0.45:\n",
    "            noise = np.random.normal(0, 0.05, img.shape)\n",
    "            img = np.clip(img + noise, 0, 1)\n",
    "        if random.random() < 0.45:\n",
    "            img = add_specular_highlight(img, intensity=1.5, radius=random.randint(10,30))\n",
    "        if random.random() < 0.45:\n",
    "            img = add_lens_flare(img, num_streaks=2)\n",
    "        if random.random() < 0.45:\n",
    "            tint_color = tuple(0.7 + 0.6*random.random() for _ in range(3))\n",
    "            img = add_tint(img, tint_color)\n",
    "\n",
    "        img = (255 * img).astype(np.uint8)\n",
    "        if not(homo):\n",
    "            return img\n",
    "        else:\n",
    "            return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModResNet2(nn.Module):\n",
    "    def __init__(self, in_chans, out):\n",
    "        super(ModResNet2, self).__init__()\n",
    "        original_model = models.resnet101(pretrained=True)\n",
    "        \n",
    "        original_model.conv1 = nn.Conv2d(\n",
    "                    in_channels=in_chans,  # Change from 3 to 1 to accept grayscale images\n",
    "                    out_channels=original_model.conv1.out_channels,\n",
    "                    kernel_size=original_model.conv1.kernel_size,\n",
    "                    stride=original_model.conv1.stride,\n",
    "                    padding=original_model.conv1.padding,\n",
    "                    bias=original_model.conv1.bias)\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            original_model.conv1,\n",
    "            original_model.bn1,\n",
    "            original_model.relu,\n",
    "            original_model.maxpool,\n",
    "            original_model.layer1,\n",
    "            original_model.layer2,\n",
    "            original_model.layer3,\n",
    "            original_model.layer4\n",
    "        )\n",
    "        self.avgpool = original_model.avgpool\n",
    "        \n",
    "        num_features = original_model.fc.in_features\n",
    "        num_out_feas = out\n",
    "        original_model.fc = nn.Linear(num_features, num_out_feas)\n",
    "        self.fc = original_model.fc\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        out_fc = self.fc(x)\n",
    "        return out_fc #out_conv#, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoseTransformer2(nn.Module):\n",
    "    def __init__(self, num_layers=12, embed_dim=512, num_heads=8, ff_dim=512, \n",
    "                 dropout=0.1, out_dim=512):\n",
    "        super().__init__()  \n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, 361, embed_dim))  # 19x19=361 tokens\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=ff_dim,\n",
    "            dropout=dropout,\n",
    "            activation='gelu',\n",
    "            batch_first=True,\n",
    "            norm_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc1 = nn.Linear(embed_dim, out_dim)\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        B = x.shape[0]\n",
    "        x = x.view(B, self.embed_dim, -1).permute(0, 2, 1)  # (B, 361, embed_dim)\n",
    "        # x = x + self.pos_embedding\n",
    "        x = self.transformer(x)\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiamesePoseNet3b_trans2d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiamesePoseNet3b_trans2d, self).__init__()\n",
    "        self.model = ModResNet2(1,512)\n",
    "        self.model2a = PoseTransformer2(embed_dim=512, out_dim=2, num_layers=2)\n",
    "        self.model2b = PoseTransformer2(embed_dim=512, out_dim=2, num_layers=2)\n",
    "        self.model2d = PoseTransformer2(embed_dim=512, out_dim=4, num_layers=2)\n",
    "    def forward(self, rgbd1):\n",
    "        f1_rgb = self.model(rgbd1[:,0:1,:,:])\n",
    "        f2_rgb = self.model(rgbd1[:,1:,:,:])\n",
    "        pfocal = self.model2a(f1_rgb - f2_rgb)\n",
    "        pcenters = self.model2b(f1_rgb - f2_rgb)\n",
    "        pquat = self.model2d(f1_rgb - f2_rgb)\n",
    "        return pfocal, pcenters, pquat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_homo(p_gt, optimz, mse_loss_f, mod1, l1=1e4, l2=1.0):\n",
    "    img_tsr, gt_out = p_gt\n",
    "    gt_out = gt_out.to(device) \n",
    "    loss = 0.0\n",
    "    pred_out = mod1(img_tsr.to(device))\n",
    "    pscl, ptrs, pquat = pred_out\n",
    "    pred_out_q = pquat/pquat.norm(p=2,dim=1,keepdim=True)\n",
    "    print(\"pred_out_q: \", pred_out_q[0,:])\n",
    "    print(\"gt_q_0: \", gt_out[0,4:])\n",
    "    print(\"pscl: \", pscl[0,:])\n",
    "    print(\"gt_scl: \", gt_out[0,0:2])\n",
    "    print(\"ptrs: \", ptrs[0,:])\n",
    "    print(\"gt_trs: \", gt_out[0,2:4])\n",
    "    loss1 = l2*mse_loss_f(pscl, gt_out[:,:2])\n",
    "    loss2 = l2*mse_loss_f(ptrs, gt_out[:,2:4])\n",
    "    loss3 = l1*mse_loss_f(pred_out_q, gt_out[:,4:])\n",
    "    print(\"loss1: \", loss1)\n",
    "    print(\"loss2: \", loss2)\n",
    "    print(\"loss3: \", loss3)\n",
    "    loss = loss1 + loss2 + loss3\n",
    "    if torch.is_tensor(loss):   \n",
    "        optimz.zero_grad()\n",
    "        loss.backward()\n",
    "        optimz.step()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        rotation_loses = [loss1, loss2, loss3, loss]\n",
    "        pq = pred_out_q.cpu().numpy()\n",
    "        pqq = np.vstack((pq[:,1], pq[:,2], pq[:,3], pq[:,0]))\n",
    "        p_eul = np.array(R.from_quat(pqq.T).as_euler('xyz',degrees=True))\n",
    "        gtq = gt_out[:,4:].cpu().numpy()\n",
    "        gqq = np.vstack((gtq[:,1], gtq[:,2], gtq[:,3], gtq[:,0]))\n",
    "        g_eul = np.array(R.from_quat(gqq.T).as_euler('xyz',degrees=True))\n",
    "        \n",
    "        out2, out3 = torch.hstack((pscl, ptrs)).cpu().numpy(), gt_out[:,0:4].cpu().numpy()\n",
    "        out2 = np.hstack((out2, p_eul))\n",
    "        out3 = np.hstack((out3, g_eul))\n",
    "        \n",
    "        for i, rot_loss in enumerate(rotation_loses):\n",
    "            if torch.is_tensor(rot_loss):\n",
    "                rotation_loses[i] = rot_loss.item()\n",
    "            else:\n",
    "                rotation_loses[i] = None\n",
    "        return (out2, out3), rotation_loses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_opt(p_gt, optimz, mse_loss_f, mod2, l4=1.0, iters=5):\n",
    "    img_tsr, uvc1  = p_gt\n",
    "    p_del_uv = mod2(img_tsr[:,0:3,:,:].to(device), img_tsr[:,3:,:,:].to(device), iters=iters, test_mode=False)\n",
    "    loss4 = 0.0\n",
    "    all_gt_uv2 = []\n",
    "    all_pd_uv2 = []\n",
    "    for kp in range(len(uvc1)):\n",
    "        u1c = uvc1[kp][:,0].long()\n",
    "        v1c = uvc1[kp][:,1].long()\n",
    "        for jp in range(len(p_del_uv)):\n",
    "            pred_uv2 = p_del_uv[jp].permute(0,2,3,1)[kp, v1c, u1c,:] + uvc1[kp][:,0:2].to(device)  \n",
    "            gt_uv2 = uvc1[kp][:,2:4]\n",
    "            loss4 = loss4 + l4*mse_loss_f(pred_uv2, gt_uv2.to(device))\n",
    "        with torch.no_grad():\n",
    "            if kp<3:\n",
    "                rind = np.random.randint(len(gt_uv2))\n",
    "                print('pred_uv2: ', pred_uv2[rind,:].flatten())\n",
    "                print('gt_uv2: ', gt_uv2[rind,:].flatten())\n",
    "                \n",
    "                vind = random.sample(range(len(gt_uv2)),100)\n",
    "                all_gt_uv2.append(gt_uv2.numpy()[vind,:])\n",
    "                all_pd_uv2.append(pred_uv2.cpu().numpy()[vind,:])\n",
    "    print(\"loss4: \", loss4)\n",
    "    loss = loss4\n",
    "    if torch.is_tensor(loss):   \n",
    "        optimz.zero_grad()\n",
    "        loss.backward()\n",
    "        optimz.step() \n",
    "    with torch.no_grad():\n",
    "        rotation_loses = [loss.cpu().numpy().item()]\n",
    "        return (all_pd_uv2, all_gt_uv2), rotation_loses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import flow_viz\n",
    "from utils import frame_utils\n",
    "from raft import RAFT\n",
    "from utils.utils import InputPadder, forward_interpolate\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas/anaconda3/envs/yolov8/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/thomas/anaconda3/envs/yolov8/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/thomas/anaconda3/envs/yolov8/lib/python3.9/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "criterion1 = nn.SmoothL1Loss().to(device)\n",
    "## Homography Alignment network\n",
    "mod1 = SiamesePoseNet3b_trans2d().to(device)\n",
    "mod1.load_state_dict(torch.load('./homo_match_comb_' +str(0)+ '.pth'))\n",
    "\n",
    "## RAFT optical-flow network\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model', help=\"restore checkpoint\")\n",
    "parser.add_argument('--dataset', help=\"dataset for evaluation\")\n",
    "parser.add_argument('--small', action='store_true', help='use small model')\n",
    "parser.add_argument('--mixed_precision', action='store_true', help='use mixed precision')\n",
    "parser.add_argument('--alternate_corr', action='store_true', help='use efficent correlation implementation')\n",
    "args, unknown = parser.parse_known_args()\n",
    "mod2 = torch.nn.DataParallel(RAFT(args))\n",
    "mod2.load_state_dict(torch.load('./raft-things.pth'))\n",
    "mod2 = mod2.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap_homo(img1, Hp_1_2, ww=640, hh=480, mxlim=3500, inv=False):\n",
    "    H, W = img1.shape[:2]\n",
    "    corners = np.array([\n",
    "        [0, 0, 1],\n",
    "        [W-1, 0, 1],\n",
    "        [W-1, H-1, 1],\n",
    "        [0, H-1, 1]\n",
    "    ], dtype=np.float32).T  \n",
    "    warped = Hp_1_2 @ corners\n",
    "    warped /= warped[2]\n",
    "\n",
    "    min_x, min_y = np.min(warped[:2],axis=1)\n",
    "    max_x, max_y = np.max(warped[:2],axis=1)\n",
    "    shift_x = -min_x if min_x < 0 else 0\n",
    "    shift_y = -min_y if min_y < 0 else 0\n",
    "\n",
    "    T = np.array([[1, 0, shift_x],\n",
    "                  [0, 1, shift_y],\n",
    "                  [0, 0, 1]], dtype=np.float32)\n",
    "    H_shifted = T @ Hp_1_2\n",
    "    new_w = max_x + shift_x\n",
    "    new_h = max_y + shift_y\n",
    "    sx = ww / new_w\n",
    "    sy = hh / new_h\n",
    "    S = np.array([[sx, 0, 0],\n",
    "                  [0, sy, 0],\n",
    "                  [0, 0, 1]], dtype=np.float32)\n",
    "    H_final = S @ H_shifted\n",
    "    blk_img = cv2.warpPerspective(img1, H_final, (ww, hh))\n",
    "    mod_params = (shift_x, shift_y, sx, sy)\n",
    "    return blk_img, H_final, mod_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_homo(img, K1, K2, R1, R2, params, inv=False, Hp=None, dft=False):\n",
    "    img = np.array(img).astype(np.uint8)\n",
    "    h, w = img.shape[:2]\n",
    "    sf, sc = params\n",
    "    K2 = np.array(K2)\n",
    "    K2[0,0] = sf[0] + K2[0,0]\n",
    "    K2[1,1] = sf[1] + K2[1,1]\n",
    "    K2[0,2] = sc[0] + K2[0,2]\n",
    "    K2[1,2] = sc[1] + K2[1,2]\n",
    "    mod_params = (0.0, 0.0, 1.0, 1.0)\n",
    "    if inv:\n",
    "        H2 = (K2@R2)@np.linalg.inv(K1@R1)\n",
    "        Hp = H2@Hp\n",
    "        Hinv = np.linalg.inv(Hp)\n",
    "        Hinv /= Hinv[2, 2]\n",
    "        rotated_image = cv2.warpPerspective(img, Hinv, (w, h))\n",
    "        return rotated_image, Hp\n",
    "    else:\n",
    "        H_o = (K2@R2)@np.linalg.inv(K1@R1)\n",
    "        H = H_o/H_o[2, 2]\n",
    "        if dft:\n",
    "            rotated_image = cv2.warpPerspective(img, H, (w, h))\n",
    "        else:\n",
    "            rotated_image, H_shifted, mod_params = remap_homo(img, H_o)\n",
    "            H_o = np.array(H_shifted)\n",
    "\n",
    "        Hf = H_o \n",
    "        return rotated_image, K2, R2, Hf, mod_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "## 3D coordinates of KLB bridge obtained from BIM\n",
    "bx_smb = [np.array([[-1.03, -10.92, 16.96],[-1.03,2.85,16.96],[-1.03,2.85,13.97],[-1.03,-10.66,13.97]]),\n",
    "          np.array([[-1.03, 2.85, 16.96],[-1.03,16.62,16.96],[-1.03,16.36,13.97],[-1.03,2.85,13.97]]),\n",
    "          np.array([[-1.03, 2.85, 13.97],[-1.03,16.36,13.97],[-1.03,16.1,10.97],[-1.03,2.85,10.97]]),\n",
    "          np.array([[-1.03,-10.66, 13.97],[-1.03,2.85,13.97],[-1.03,2.85,10.97],[-1.03,-10.39,10.97]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "## The calibration parameters had already been obtained using INAF\n",
    "## Define camera intrinsic matrix\n",
    "K_mm = np.array([[508.3997, 0, 316.0652],[0,677.8663,254.0068],[0, 0, 1]])\n",
    "nimg_0 = [13,19,22,21,48,65,52,54,55,31,32,7,14]\n",
    "nimg_g = list(itertools.combinations(nimg_0, 2))\n",
    "klb_dir = './smart_bridge2/'\n",
    "IMGS, TRNS, QUTS = [], [], []\n",
    "for idx in nimg_0:\n",
    "    img_idx = cv2.imread(klb_dir+'img'+str(idx)+'.png')\n",
    "    IMGS.append(cv2.cvtColor(img_idx,cv2.COLOR_BGR2RGB)) \n",
    "    trs = np.load(klb_dir+'trans_'+str(idx)+'.npy').flatten()\n",
    "    qts = np.load(klb_dir+'quat_'+str(idx)+'.npy').flatten()\n",
    "    TRNS.append(trs) \n",
    "    QUTS.append(qts)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ffbx(K_mm, Rts, xyz_0, trs, th=100):\n",
    "    zuv0 = K_mm@Rts@(xyz_0.T - trs.reshape(-1,1))\n",
    "    uv_0 = (zuv0[0:2,:]/zuv0[2:,:]).astype(np.int16)\n",
    "    return uv_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generation of patches\n",
    "BXMs = []\n",
    "n_patches = 4\n",
    "for idx in nimg_0:\n",
    "    trs = np.load(klb_dir+'trans_'+str(idx)+'.npy').flatten()\n",
    "    qts = np.load(klb_dir+'quat_'+str(idx)+'.npy').flatten() #0.95\n",
    "    Rts = np.array(R.from_quat([qts[1],qts[2],qts[3],qts[0]]).as_matrix())\n",
    "    xyz_0 = np.array([[-1.03, -10.92, 16.96],[-1.03,2.85,16.96],[-1.03,2.85,13.97],[-1.03,-10.66,13.97]])\n",
    "    xyz_1 = np.array([[-1.03, 2.85, 16.96],[-1.03,16.62,16.96],[-1.03,16.36,13.97],[-1.03,2.85,13.97]])\n",
    "    xyz_2 = np.array([[-1.03, 2.85, 13.97],[-1.03,16.36,13.97],[-1.03,16.1,10.97],[-1.03,2.85,10.97]])\n",
    "    xyz_3 = np.array([[-1.03,-10.66, 13.97],[-1.03,2.85,13.97],[-1.03,2.85,10.97],[-1.03,-10.39,10.97]])\n",
    "    uv_0 = calc_ffbx(K_mm, Rts, xyz_0, trs)\n",
    "    uv_1 = calc_ffbx(K_mm, Rts, xyz_1, trs)\n",
    "    uv_2 = calc_ffbx(K_mm, Rts, xyz_2, trs)\n",
    "    uv_3 = calc_ffbx(K_mm, Rts, xyz_3, trs)\n",
    "    BXMs.append([uv_0.T, uv_1.T, uv_2.T, uv_3.T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_mskk(im, uv_1):\n",
    "    im = np.array(im).astype(np.uint8)\n",
    "    hh,ww = im.shape[0:2]\n",
    "    msk = np.zeros((hh,ww),dtype=np.uint8)\n",
    "    pts = np.array(uv_1[0:2,:]).T.astype(np.int32)\n",
    "    cv2.fillPoly(msk, pts[np.newaxis,:,:], 1)\n",
    "    if len(im.shape)>2:\n",
    "        msk = np.stack([msk]*3,-1)\n",
    "    imgi = msk*im\n",
    "    return imgi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fratio(uv_1, uv_2, th=0.2, w=640, h=480):\n",
    "    uv_2[0,uv_2[0,:]<0] = 0\n",
    "    uv_2[0,uv_2[0,:]>w-1] = w-1\n",
    "    uv_2[1,uv_2[1,:]<0] = 0\n",
    "    uv_2[1,uv_2[1,:]>h-1] = h-1\n",
    "    vmin,vmax = np.nanmin(uv_2[1,:])/h,np.nanmax(uv_2[1,:])/h\n",
    "    umin,umax = np.nanmin(uv_2[0,:])/w,np.nanmax(uv_2[0,:])/w\n",
    "    a2 = (vmax-vmin)*(umax-umin)\n",
    "    vmin1,vmax1 = np.nanmin(uv_1[1,:])/h,np.nanmax(uv_1[1,:])/h\n",
    "    umin1,umax1 = np.nanmin(uv_1[0,:])/w,np.nanmax(uv_1[0,:])/w\n",
    "    a1 = (vmax1-vmin1)*(umax1-umin1)\n",
    "    flag = (a2/a1)>=th\n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "#This holds for a 640x480 image frame - can be modified accordingly\n",
    "U2v, V2v = np.arange(640),np.arange(480)\n",
    "U2v, V2v = np.meshgrid(U2v, V2v)\n",
    "U2v, V2v = U2v.flatten(), V2v.flatten()\n",
    "onsv = np.ones_like(U2v)\n",
    "U2v1 = np.vstack((U2v,V2v,onsv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthetic_depth_surface(UV, curvature=0.0, max_depth_diff=1.0, center=None, coff=0.5):\n",
    "    UV = np.asarray(UV)\n",
    "    cid = np.random.randint(len(UV))\n",
    "    center = UV[cid,:]\n",
    "    d_norm = np.linalg.norm(UV - center, axis=1)\n",
    "    rnd = random.choice([-1.0,1.0])\n",
    "    surface = rnd * (np.exp(-curvature * d_norm**2) - 1.0)\n",
    "    depth = surface * max_depth_diff + coff\n",
    "    return depth.reshape(480,640)\n",
    "    \n",
    "def synthetic_trans3D(t1,R1,img1,K1,nnmax=1300):\n",
    "    rnd = np.random.uniform(0,1.0,1)\n",
    "    if rnd < 0.5:\n",
    "        dt = np.random.uniform(-0.1,0.1,3).reshape(-1,1)\n",
    "        dr = np.random.uniform(-5,5,3)\n",
    "    elif (rnd>=0.5) and (rnd<0.7):\n",
    "        dt = np.random.uniform(-0.5,0.5,3).reshape(-1,1)\n",
    "        dr = np.random.uniform(-10,10,3)\n",
    "    else:\n",
    "        dt = np.random.uniform(-1.5,1.5,3).reshape(-1,1)\n",
    "        dr = np.random.uniform(-15,15,3)\n",
    "    max_d = np.random.uniform(1,3,1)\n",
    "    cv = np.random.uniform(0.0,2.0,1) #np.random.uniform(-0.1,0.1)\n",
    "    t2 = t1 + dt\n",
    "    coff = t1[0,0] + np.random.uniform(-1.5,1.5,1)\n",
    "    r1 = np.array(R.from_matrix(R1).as_euler('xyz',degrees=True))\n",
    "    r2 = r1 + dr\n",
    "    R2 = np.array(R.from_euler('xyz',r2,degrees=True).as_matrix())\n",
    "    z2_0 = synthetic_depth_surface(U2v1[0:2,:].T, curvature=cv, max_depth_diff=max_d, coff=coff)\n",
    "    z2 = z2_0[U2v1[1,:],U2v1[0,:]]\n",
    "    z1u1 = K1@R1@(np.linalg.inv(K1@R2)@(z2*U2v1) + t2-t1)\n",
    "    z1u1 = z1u1[0:2,:] / z1u1[2:,:]\n",
    "    u1p, v1p = z1u1[0,:], z1u1[1,:]\n",
    "    ffg = (u1p>=0) * (u1p<640) * (v1p>=0) * (v1p<480)\n",
    "    u1p, v1p = u1p[ffg].astype(np.int16), v1p[ffg].astype(np.int16)\n",
    "    if len(u1p)>=1000:\n",
    "        u2p, v2p = U2v[ffg], V2v[ffg]\n",
    "        blk_img = np.zeros_like(img1)\n",
    "        blk_img[v2p,u2p,:] = img1[v1p,u1p,:]\n",
    "        vv_2n, uu_2n, _ = np.where(blk_img > 0)\n",
    "        if len(vv_2n)>=100*100:\n",
    "            on2 = np.ones_like(vv_2n)\n",
    "            U2v1_n = np.vstack((uu_2n, vv_2n, on2))\n",
    "            z2_ = z2_0[vv_2n,uu_2n]\n",
    "            z1u1n = K1@R1@(np.linalg.inv(K1@R2)@(z2_*U2v1_n) + t2-t1)\n",
    "            z1u1n = z1u1n[0:2,:] / z1u1n[2:,:]\n",
    "            u1pn, v1pn = z1u1n[0,:], z1u1n[1,:]\n",
    "            ffg = (u1pn>=0) * (u1pn<640) * (v1pn>=0) * (v1pn<480)\n",
    "            UV2n = np.vstack((uu_2n[ffg], vv_2n[ffg])).T\n",
    "            UV1n = np.vstack((u1pn[ffg], v1pn[ffg])).T\n",
    "            if len(UV1n)>nnmax:\n",
    "                piddx = random.sample(range(len(UV1n)),nnmax)\n",
    "                UV1n, UV2n = UV1n[piddx,:], UV2n[piddx,:]\n",
    "            return blk_img, torch.tensor(UV1n), torch.tensor(UV2n)\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comb_imgs2(pid, pid2, imgi, T1_,R1_, params, K1, K2, R2, R3, sz=300, homo=False, viz=False):\n",
    "    K2 = np.array(K2)\n",
    "    K1 = np.array(K1)\n",
    "    if not(homo):\n",
    "        imgi = np.array(imgi)\n",
    "    else:\n",
    "        imgi = cv2.cvtColor(imgi, cv2.COLOR_BGR2GRAY).astype(np.uint8) \n",
    "    hhn, wwn = imgi.shape[0:2] \n",
    "    ptz_tsr_list = []\n",
    "    ptz_opti_data = []\n",
    "    ptz_tsr_list_viz = []\n",
    "    mod_params = []\n",
    "    bx_smb = BXMs[pid2]\n",
    "    for kk, ptz in enumerate([bx_smb[pid]]):\n",
    "        if ptz is not None:\n",
    "            uv_ = ptz.T\n",
    "            img1_pz = comp_mskk(imgi, uv_.astype(np.int16))\n",
    "            imgiii = np.array(imgi).astype(np.uint8)\n",
    "            rpt = np.random.uniform(0.0,1.0,1)\n",
    "            if rpt < 0.25:\n",
    "                ph_trans = True\n",
    "                imgiii = pt_trans(imgiii, ph_trans, homo)\n",
    "            img1_pz_ = comp_mskk(imgiii, uv_.astype(np.int16))\n",
    "            FLG = False\n",
    "            \n",
    "            rn_opt = np.random.uniform(0,1)\n",
    "            if not(homo) and rn_opt<0.3:\n",
    "                osyn = synthetic_trans3D(T1_,R1_,img1_pz_,K1)\n",
    "                if osyn:\n",
    "                    img2_pz, coords1, coords2 = osyn\n",
    "                    m_prms = (0.0, 0.0, 1.0, 1.0)\n",
    "                    mod_params.append(m_prms)\n",
    "                    FLG = True \n",
    "            else:\n",
    "                rmd = random.choice([True, False])\n",
    "                img2_pz, _, _, Hp, m_prms = construct_homo(img1_pz_, K1, K2, R2, R3, params, dft=rmd)\n",
    "                ones_ = np.ones_like(uv_[0,:])\n",
    "                uv_1 = np.vstack((uv_,ones_))\n",
    "                uv_2 = Hp @ uv_1\n",
    "                uv_2 = uv_2[0:2,:]/uv_2[2:,:]\n",
    "                ohom = fratio(np.array(uv_), uv_2, th=0.4, w=wwn, h=hhn)\n",
    "                if ohom:\n",
    "                    mskk = np.zeros((hhn,wwn),dtype=np.uint8)\n",
    "                    pts = np.array(uv_).T.astype(np.int32)\n",
    "                    cv2.fillPoly(mskk, pts[np.newaxis,:,:], 1)\n",
    "                    vv_1, uu_1 = np.where(mskk > 0)\n",
    "                    ones_1 = np.ones_like(vv_1)\n",
    "                    uv_op = np.vstack((uu_1, vv_1, ones_1))\n",
    "                    uv_2op = Hp @ uv_op\n",
    "                    uv_2op = uv_2op[0:2,:]/uv_2op[2:,:]\n",
    "                    viz_flg = (uv_2op[0,:]>=0) * (uv_2op[0,:]<wwn) * (uv_2op[1,:]>=0) * (uv_2op[1,:]<hhn)\n",
    "                    coords1 = torch.tensor(np.vstack((uu_1, vv_1)).T)[viz_flg,:]\n",
    "                    coords2 = torch.tensor(uv_2op.T).float()[viz_flg,:]\n",
    "                    mod_params.append(m_prms)\n",
    "                    FLG = True\n",
    "            if FLG:\n",
    "                if len(coords1)>=100:\n",
    "                    opti_data = torch.hstack((coords1,coords2))\n",
    "                    ptz_opti_data.append(opti_data)\n",
    "\n",
    "                    if not(homo):\n",
    "                        img_tsr1 = torch.tensor(img1_pz).permute(2,0,1)\n",
    "                        img_tsr2 = torch.tensor(img2_pz).permute(2,0,1)\n",
    "                        comb_tsr = torch.concat([img_tsr1, img_tsr2],0).float()\n",
    "                    else:\n",
    "                        img_tsr1 = F.interpolate(torch.tensor(img1_pz/255.0).unsqueeze(0).unsqueeze(0), size=(sz,sz), mode='bilinear', align_corners=False).squeeze(0).squeeze(0)\n",
    "                        img_tsr2 = F.interpolate(torch.tensor(img2_pz/255.0).unsqueeze(0).unsqueeze(0), size=(sz,sz), mode='bilinear', align_corners=False).squeeze(0).squeeze(0)\n",
    "                        comb_tsr = torch.stack([img_tsr1, img_tsr2],0).float()\n",
    "\n",
    "                    ptz_tsr_list.append(comb_tsr)\n",
    "                    if viz:\n",
    "                        if homo:\n",
    "                            vis = np.hstack((img1_pz, img2_pz))\n",
    "                        else:\n",
    "                            h1, w1 = img1_pz.shape[:2]; h2, w2 = img2_pz.shape[:2]\n",
    "                            vis = np.zeros((max(h1,h2), w1+w2, 3), dtype=np.uint8) \n",
    "                            vis[:h1, :w1, :] = img1_pz\n",
    "                            vis[:h2, w1:w1+w2, :] = img2_pz\n",
    "                            pts1 = coords1.numpy()\n",
    "                            pts2 = coords2.numpy()\n",
    "                            npmax = 10\n",
    "                            if len(pts1)>npmax:\n",
    "                                nnid = random.sample(range(len(pts1)),npmax)\n",
    "                                pts1_ = pts1[nnid,:]\n",
    "                                pts2_ = pts2[nnid,:]\n",
    "                                for (x1,y1), (x2,y2) in zip(pts1_, pts2_):\n",
    "                                    color = (0,255,0)\n",
    "                                    pt1 = (int(x1), int(y1))\n",
    "                                    pt2 = (int(x2)+w1, int(y2))\n",
    "                                    cv2.line(vis, pt1, pt2, color, 1, cv2.LINE_AA)\n",
    "                                    cv2.circle(vis, pt1, 4, color, -1)\n",
    "                                    cv2.circle(vis, pt2, 4, color, -1)\n",
    "\n",
    "                        ptz_tsr_list_viz.append(vis)\n",
    "    return ptz_tsr_list, ptz_tsr_list_viz, ptz_opti_data, mod_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_datagen(pid, Kmm,  sz=300, viz=False, nrep=30, homo=False):\n",
    "    all_dat = []\n",
    "    img12_tsr_all = []\n",
    "    opt_data_all = []\n",
    "    imgs_samps = []\n",
    "    vizxx = []\n",
    "\n",
    "    K1 = np.array(Kmm)\n",
    "    K1_ = np.array(K1)\n",
    "    K1 = np.array(K1)\n",
    "    ofx, ofy, ocx, ocy = K1[0,0],K1[1,1],K1[0,2],K1[1,2]\n",
    "    ofs = np.array([ofx,ofy]).flatten()\n",
    "    ocs = np.array([ocx,ocy]).flatten()\n",
    "    for _ in range(nrep):\n",
    "        idx = np.random.randint(len(nimg_0))\n",
    "        imgs_samps.append(idx)\n",
    "        imgi = IMGS[idx]\n",
    "        try:\n",
    "            T1_ = TRNS[idx].reshape(-1,1)\n",
    "            qi = QUTS[idx].tolist()\n",
    "            ru = R.from_quat([qi[1],qi[2],qi[3],qi[0]]).as_euler('xyz',degrees=True)\n",
    "        except:\n",
    "            T1_ = np.zeros(3).reshape(-1,1)\n",
    "            ru = np.zeros(3)\n",
    "        R1_ = R.from_euler('xyz',ru,degrees=True).as_matrix()\n",
    "        rv = np.random.uniform(0.0,1.0,1)\n",
    "        if rv < 0.35:\n",
    "            scale = np.random.uniform(-10.0,10.0,2)\n",
    "            trans = np.random.uniform(-10.0,10.0,2)\n",
    "            angv = np.random.uniform(-1.0, 1.0, 3)\n",
    "        elif (rv > 0.35) and (rv < 0.5):\n",
    "            scale = np.random.uniform(-80.0, 80.0,2)\n",
    "            trans = np.random.uniform(-80.0, 80.0,2)\n",
    "            angv = np.random.uniform(-5.0, 5.0, 3)\n",
    "        else:\n",
    "            scale = np.random.uniform(-180.0, 180.0,2)\n",
    "            trans = np.random.uniform(-120.0, 120.0,2)\n",
    "            angv = np.random.uniform(-30.0, 30.0, 3)\n",
    "\n",
    "        R2 = R.from_euler('xyz', angv+ru, degrees=True).as_matrix()\n",
    "        q2g = np.array(R.from_matrix(R2).as_quat())\n",
    "        q2g = (q2g/np.linalg.norm(q2g)).tolist()\n",
    "        R_c1_c2 = R2@R1_.T\n",
    "        angdd = np.array(R.from_matrix(R_c1_c2).as_quat())\n",
    "        angdd = angdd/np.linalg.norm(angdd)\n",
    "        q_d = np.array([angdd[-1], angdd[0], angdd[1], angdd[2]])\n",
    "        params = (scale, trans)\n",
    "        K2 = np.array(K1_)\n",
    "        out1 = comb_imgs2(pid, idx, imgi, T1_, R1_, params, K1, K2, R1_, R2, sz=sz, homo=homo, viz=viz)\n",
    "        if out1 is not None:\n",
    "            img12_tsr_lst, img12_viz, ptz_opti_data, m_prms = out1\n",
    "            if len(img12_tsr_lst)>=1:\n",
    "                for kl in range(len(img12_tsr_lst)):\n",
    "                    sfxy = np.array(m_prms[kl][0:2]).flatten()\n",
    "                    scxy = np.array(m_prms[kl][2:]).flatten()\n",
    "                    nfs_ = scxy * (ofs + params[0])\n",
    "                    nocs_ = scxy * (ocs + sfxy + params[1])\n",
    "                    scale_ = nfs_ - ofs\n",
    "                    trans_ = nocs_ - ocs \n",
    "                    dat_v = np.hstack((scale_, trans_, q_d))\n",
    "                    all_dat.append(dat_v.flatten().tolist())\n",
    "                    img12_tsr_all.append(img12_tsr_lst[kl])\n",
    "                    opt_data_all.append(ptz_opti_data[kl])\n",
    "                    if viz:\n",
    "                        vizxx.append(img12_viz[kl])\n",
    "                        \n",
    "    if len(img12_tsr_all)>=1:\n",
    "        iddx = np.arange(len(all_dat))\n",
    "        np.random.shuffle(iddx) \n",
    "        iddx = iddx.tolist()\n",
    "        print(\"len_all_dat: \", len(all_dat))  \n",
    "        all_dat_tsr = torch.tensor(all_dat).float()[iddx,:]\n",
    "        img12_tsr_ls = torch.stack(img12_tsr_all,0).float()[iddx,:,:,:]\n",
    "        opt_data_all_ = [opt_data_all[nb] for nb in iddx]\n",
    "    else:\n",
    "        all_dat_tsr, img12_tsr_ls, opt_data_all_ = [], [], []\n",
    "    return img12_tsr_ls, all_dat_tsr, opt_data_all_, vizxx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_k(fs, cs, Kn):\n",
    "    Kn = np.array(Kn)   \n",
    "    Kn[0,0] = fs[0] + Kn[0,0]\n",
    "    Kn[1,1] = fs[1] + Kn[1,1]\n",
    "    Kn[0,2] = cs[0] + Kn[0,2]\n",
    "    Kn[1,2] = cs[1] + Kn[1,2]\n",
    "    return Kn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calRfq(qn):\n",
    "    Rm = np.array(R.from_quat([qn[1],qn[2],qn[3],qn[0]]).as_matrix())\n",
    "    return Rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homo_unwarp(img, Hn, w=640, h=480):\n",
    "    img = np.array(img).astype(np.uint8)\n",
    "    Hinv = np.linalg.inv(Hn)\n",
    "    Hinv /= Hinv[2, 2]\n",
    "    rotated_image = cv2.warpPerspective(img, Hinv, (w, h))\n",
    "    return rotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_img_valid(u2_p_, ww=640, hh=480):\n",
    "    u2_p = np.array(u2_p_)\n",
    "    fl = (u2_p[0,:]>=0) * (u2_p[0,:]<ww) * (u2_p[1,:]>=0) * (u2_p[1,:]<hh)\n",
    "    u2_pp = u2_p[:,fl]\n",
    "    if u2_pp.shape[1]<10:\n",
    "        return False\n",
    "    else:\n",
    "        dww = np.max(u2_pp[0,:]) - np.min(u2_pp[0,:])\n",
    "        dhh = np.max(u2_pp[1,:]) - np.min(u2_pp[1,:])\n",
    "        if dww>=50 and dhh>=50:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_patch_algn(modn, pid, Kmm, iters=5, sz=300, viz=False, nnmax=5000):\n",
    "    modd = modn.eval()\n",
    "    with torch.no_grad():\n",
    "        idx = np.random.randint(len(nimg_0))\n",
    "        print(\"img_indx: \", nimg_0[idx])\n",
    "        img1 = IMGS[idx]\n",
    "        img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY).astype(np.uint8) \n",
    "        \n",
    "        try:\n",
    "            t1 = TRNS[idx].reshape(-1,1)\n",
    "            q1 = QUTS[idx].tolist()\n",
    "            R1_ = np.array(R.from_quat([q1[1],q1[2],q1[3],q1[0]]).as_matrix())\n",
    "            ru1 = np.array(R.from_matrix(R1_).as_euler('xyz',degrees=True))\n",
    "        except:\n",
    "            t1 = np.zeros(3)\n",
    "            ru1 = np.zeros(3)\n",
    "            R1_ = np.array(R.from_euler('xyz', ru1, degrees=True).as_matrix())\n",
    "        \n",
    "        rv = np.random.uniform(0.0,1.0,1)\n",
    "        if rv < 0.3:\n",
    "            gt_scale = np.random.uniform(-5.0,5.0,2)\n",
    "            gt_trans = np.random.uniform(-5.0,5.0,2)\n",
    "            angv = np.random.uniform(-5.0, 5.0, 3)\n",
    "        elif (rv > 0.3) and (rv < 0.6):\n",
    "            gt_scale = np.random.uniform(-100.0, 100.0,2)\n",
    "            gt_trans = np.random.uniform(-100.0, 100.0,2)\n",
    "            angv = np.random.uniform(-15.0, 15.0, 3)\n",
    "        else:\n",
    "            gt_scale = np.random.uniform(-200,200,2)\n",
    "            gt_trans = np.random.uniform(-200,200,2)\n",
    "            shear = np.random.uniform(-200.0,200.0,2)\n",
    "            angv = np.random.uniform(-30.0, 30.0, 3)\n",
    "        \n",
    "        R2_ = np.array(R.from_euler('xyz', ru1+angv, degrees=True).as_matrix())\n",
    "        params = (gt_scale, gt_trans)\n",
    "        K1 = np.array(Kmm)\n",
    "        K2 = np.array(Kmm)\n",
    "\n",
    "        hhn, wwn = img1.shape[0:2]\n",
    "        ascores, a_imgs = [], []\n",
    "        p_imgs = []   \n",
    "        bx_smb = BXMs[idx][pid]\n",
    "        ptz_ids = 100*torch.eye(4).float()\n",
    "        for kk, ptz in enumerate([bx_smb]): \n",
    "            if ptz is not None:\n",
    "                uv_ = ptz.T\n",
    "                img1_0 = comp_mskk(img1, uv_.astype(np.int16))\n",
    "                rmd = random.choice([True,False])\n",
    "                img2_0, _, _, H_o, m0_prms = construct_homo(img1_0, K1, K2, R1_, R2_, params, dft=rmd)\n",
    "                ones_ = np.ones_like(uv_[0,:])\n",
    "                uv_1 = np.vstack((uv_,ones_))\n",
    "                uv_2 = H_o @ uv_1\n",
    "                uv_2 = uv_2[0:2,:]/uv_2[2:,:]\n",
    "                flg1 = fratio(np.array(uv_), uv_2, th=0.45)\n",
    "                if flg1:\n",
    "                    img2_0 = np.array(img2_0).astype(np.uint8) \n",
    "                    ones_ = np.ones_like(uv_[0,:])\n",
    "                    uv_1 = np.vstack((uv_,ones_))\n",
    "                    uv_2 = H_o @ uv_1\n",
    "                    uv_2 = uv_2[0:2,:]/uv_2[2:,:]\n",
    "                    scores_ind = []\n",
    "                    scores = []\n",
    "                    imgs_aln = []\n",
    "                    img1_00, img2_00 = np.array(img1_0).astype(np.uint8), np.array(img2_0).astype(np.uint8)\n",
    "                    img_tsr10 = F.interpolate(torch.tensor(img1_00/255.0).unsqueeze(0).unsqueeze(0), size=(sz,sz), mode='bilinear', align_corners=False).squeeze(0).squeeze(0)\n",
    "                    mskk = np.zeros((hhn,wwn),dtype=np.uint8)\n",
    "                    pts = np.array(uv_).T.astype(np.int32)\n",
    "                    cv2.fillPoly(mskk, pts[np.newaxis,:,:], 1)\n",
    "                    vv_1n, uu_1n = np.where(mskk > 0)\n",
    "                    piddx = random.sample(range(len(vv_1n)),nnmax)\n",
    "                    vv_1, uu_1 = vv_1n[piddx], uu_1n[piddx]\n",
    "                    ones_1 = np.ones_like(vv_1)\n",
    "                    u11_i = np.vstack((uu_1, vv_1, ones_1))\n",
    "                    u21_i = H_o @ u11_i\n",
    "                    u21_i = u21_i/u21_i[2:,:]\n",
    "                    u1_i, u2_i = u11_i[0:2,:], u21_i[0:2,:]\n",
    "                    u22_i = np.vstack((u2_i, ones_1))\n",
    "\n",
    "                    H12_c = np.eye(3)\n",
    "                    for j in range(iters):\n",
    "                        img_tsr1 = F.interpolate(torch.tensor(img1_0/255.0).unsqueeze(0).unsqueeze(0), size=(sz,sz), mode='bilinear', align_corners=False).squeeze(0).squeeze(0)\n",
    "                        img_tsr2 = F.interpolate(torch.tensor(img2_0/255.0).unsqueeze(0).unsqueeze(0), size=(sz,sz), mode='bilinear', align_corners=False).squeeze(0).squeeze(0)\n",
    "                        comb_tsr1 = torch.stack([img_tsr1, img_tsr2],0).float()\n",
    "                        comb_tsr_btz = comb_tsr1.unsqueeze(0)\n",
    "                        pred_ptz = modd(comb_tsr_btz.to(device))\n",
    "                        fscale, cscale, quat = pred_ptz\n",
    "                        fs, cs  = fscale.cpu().numpy(), cscale.cpu().numpy()\n",
    "                        sh = np.zeros((2,2))\n",
    "                        qtn = quat/quat.norm(p=2,dim=1,keepdim=True)\n",
    "                        qtn = qtn.cpu().numpy()\n",
    "                        \n",
    "                        K12 = update_k(fs[0,:], cs[0,:], K1)\n",
    "                        R12 = calRfq(qtn[0,:].flatten().tolist())\n",
    "                        H12 = K12 @ R12 @ np.linalg.inv(K1)\n",
    "                        H12_c = np.array(H12 @ H12_c)\n",
    "                        img2_0 = homo_unwarp(img2_00, np.array(H12_c))\n",
    "                        u2_p = H12_c @ u11_i\n",
    "                        u2_p = u2_p[0:2,:]/u2_p[2:,:]\n",
    "                        if not(comp_img_valid(u2_p)):\n",
    "                            break\n",
    "                        d12 = np.mean(np.abs(u2_i-u2_p))\n",
    "                        scores.append(d12)\n",
    "                        scores_ind.append(d12)\n",
    "                        imgs_aln.append((img2_0, img1_0))\n",
    "                    if len(scores)>=1:\n",
    "                        b_ind = np.argmin(scores)\n",
    "                        b_score = np.min(scores)\n",
    "                        print(\"b_score: \", b_score, ' pixels')\n",
    "                        img1_00_ = cv2.resize(img1_00,(sz,sz),interpolation=cv2.INTER_LINEAR)\n",
    "                        img2_pp = cv2.resize(imgs_aln[b_ind][0],(sz,sz),interpolation=cv2.INTER_LINEAR) #cv2.resize(imgs_aln[b_ind][0],(sz,sz),interpolation=cv2.INTER_LINEAR)\n",
    "                        img2_00_p = cv2.resize(img2_00,(sz,sz),interpolation=cv2.INTER_LINEAR)\n",
    "                        \n",
    "                        cv2.putText(img1_00_, 'Src', (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "                        cv2.putText(img2_00_p, 'Trg.', (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "                        cv2.putText(img2_pp, 'Rect. Trg.', (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "                        img1_comb = np.hstack((img1_00_, img2_pp, img2_00_p)) #\n",
    "                        ascores.append(b_score) \n",
    "                        a_imgs.append(img1_comb)\n",
    "                    else:\n",
    "                        ascores.append(None)\n",
    "                else:\n",
    "                    ascores.append(None)\n",
    "        else:\n",
    "            ascores.append(None)\n",
    "        clr = True\n",
    "        if viz:\n",
    "            if len(a_imgs)>=1:\n",
    "                clr = False  \n",
    "                clear_output(wait=True)\n",
    "                aimgs = np.vstack(a_imgs)\n",
    "                plt.figure(figsize=(25,10))\n",
    "                plt.imshow(aimgs, cmap='gray')\n",
    "                plt.show()\n",
    "                     \n",
    "        return ascores[0], clr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typplot(gts, preds, dims, ceps, title, mk):\n",
    "    plt.figure(figsize=(18, 5))\n",
    "    for i in range(gts.shape[1]):\n",
    "        plt.subplot(1,gts.shape[1],i+1)\n",
    "        plt.plot(gts[:,i], '--*', label='GT_'+mk+' '+str(dims[i]))\n",
    "        plt.plot(preds[:,i], '--*', label='pred_'+mk+' '+str(dims[i])+'\\nCEP: '+str(round(ceps[i],3)))\n",
    "        plt.legend()\n",
    "    plt.suptitle(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_progress_homo(comb_loss, preds, gts, hscores, clr):  \n",
    "\n",
    "    if clr:\n",
    "        clear_output(wait=True)\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.plot(hscores)\n",
    "    plt.suptitle('Patches pixel misalignment')\n",
    "    ceps = np.median(np.abs(preds - gts), 0)\n",
    "    plt.figure(figsize=(18, 5))\n",
    "    for i in range(len(comb_loss[0])): #5\n",
    "        plt.subplot(1, len(comb_loss[0]), i+1)\n",
    "        l_i = []\n",
    "        for loss_k in comb_loss:\n",
    "            if loss_k[i] is not None:\n",
    "                l_i.append(loss_k[i])\n",
    "        if len(l_i)>1:\n",
    "            tag =  'loss_' \n",
    "            plt.plot(l_i, label=tag+str(i+1)+'\\nCur. loss: '+\n",
    "                    str(round(l_i[-1],5)))\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.legend()\n",
    "    plt.suptitle('param losses.')\n",
    "    dims = ['X', 'Y', 'Z']\n",
    "    typplot(gts[:,0:2], preds[:,0:2], dims, ceps[0:2], 'Scale focal', 'sf')\n",
    "    typplot(gts[:,2:4], preds[:,2:4], dims, ceps[2:4], 'Scale img. centers', 'sc')\n",
    "    typplot(gts[:,4:], preds[:,4:], dims, ceps[4:], 'Rotation transformation plots', 'rot')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "homo_models = './PATCH_HOMO_MODELS/'\n",
    "if not os.path.exists(homo_models):\n",
    "    os.makedirs(homo_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fit and evaluate Homography Alignment Network for each patch for all images in the collection\n",
    "for pid in range(n_patches):\n",
    "    prev_error = 100000\n",
    "    hscomb = [100,100]\n",
    "    Nmax = 16 #Select according to GPU capacity\n",
    "    Nepoch = 600\n",
    "    Ne_max = 3500 # Set the maximum number of training episode \n",
    "    mod1 = mod1.train().to(device)\n",
    "    optz_pid = optim.Adam(mod1.parameters(), lr=1e-4)\n",
    "    done = False\n",
    "    epoch = 0\n",
    "    comb_rel_quat, gt_rel_quat, comb_loss = [], [], []\n",
    "    hscores = [100, 100]\n",
    "    while not(done):\n",
    "        print(\"current_patch: \", pid)\n",
    "        out3 = online_datagen(pid, K_mm, sz=300, viz=False, nrep=10, homo=True)\n",
    "        if len(out3[0])>=5:\n",
    "            p_gt = (out3[0][0:Nmax,:,:,:], out3[1][0:Nmax,:])\n",
    "            out_preds = None\n",
    "            if len(p_gt[0]>1): \n",
    "                out_preds = training_homo(p_gt, optz_pid, criterion1, mod1) \n",
    "            if out_preds is not None:\n",
    "                comb_rel_quat.append(out_preds[0][0])\n",
    "                gt_rel_quat.append(out_preds[0][1])\n",
    "                comb_loss.append(out_preds[1])\n",
    "                mme_pixels = None  \n",
    "                preds, gts = np.vstack(comb_rel_quat), np.vstack(gt_rel_quat)\n",
    "                if epoch%20==0:\n",
    "                    vizb = True\n",
    "                else:\n",
    "                    vizb = False\n",
    "                out4 = eval_patch_algn(mod1, pid, K_mm, iters=10, sz=300, viz=vizb)\n",
    "                if out4[0] is not None:\n",
    "                    hscores.append(out4[0])\n",
    "\n",
    "                mme_pixels_ = np.median(hscomb)\n",
    "                print(\"mean error homo: \", mme_pixels_, ' pixels')\n",
    "                if epoch%20==0:\n",
    "                    out_3 = plot_progress_homo(comb_loss, preds,  gts, hscores, out4[-1])\n",
    "                    cum_quat = out_3   \n",
    "                if mme_pixels_ is not None:\n",
    "                    if mme_pixels_<=prev_error and epoch>=50:\n",
    "                        torch.save(mod1.state_dict(), homo_models+'/homo_match_comb_' +str(pid)+ '.pth')\n",
    "                        prev_error = mme_pixels_\n",
    "                    if (epoch>=Nepoch) and (prev_error<=4.5):\n",
    "                        done = True\n",
    "                    elif epoch>=Ne_max:\n",
    "                        done = True\n",
    "            epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_progress_opt(a_uv_pd, a_uv_gt, comb_loss):  \n",
    "    clear_output(wait=True)   \n",
    "    plt.figure(figsize=(6, 3))\n",
    "    for i in range(len(comb_loss[0])): #5\n",
    "        plt.subplot(1, len(comb_loss[0]), i+1)\n",
    "        l_i = []\n",
    "        for loss_k in comb_loss:\n",
    "            if loss_k[i] is not None:\n",
    "                l_i.append(loss_k[i])\n",
    "        \n",
    "        if len(l_i)>1:\n",
    "            tag =  'loss_' \n",
    "            plt.plot(l_i, label=tag+str(i+1)+'\\nCur. loss: '+\n",
    "                    str(round(l_i[-1],5)))\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.legend()\n",
    "    plt.suptitle('loss history')\n",
    "    if a_uv_pd is not None:\n",
    "        cep_u = np.round(np.median(np.abs(a_uv_gt - a_uv_pd),0),2)\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(a_uv_gt[:,0], '*-', label='GT')\n",
    "        plt.plot(a_uv_pd[:,0], '--', label='pred_u'+'\\nCEP: '+str(cep_u[0])+' pix.')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(a_uv_gt[:,1], '*-', label='GT')\n",
    "        plt.plot(a_uv_pd[:,1], '--', label='pred_v'+'\\nCEP: '+str(cep_u[1])+' pix.')\n",
    "        plt.legend()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_models = './PATCH_OPT_MODELS/'\n",
    "if not os.path.exists(opt_models):\n",
    "    os.makedirs(opt_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finetune RAFT optical flow for pixel-wise matching\n",
    "\n",
    "for pid in range(n_patches):\n",
    "    prev_error = 100000\n",
    "    Nmax = 12\n",
    "    Nepoch = 600\n",
    "    Ne_max = 2000\n",
    "    mod2 = mod2.train().to(device)\n",
    "    optimz = optim.Adam([{'params': mod2.parameters(), 'lr': 1e-4}])\n",
    "    done = False\n",
    "    epoch = 0\n",
    "    uv_pds, uv_gts = [], []\n",
    "    comb_loss = []\n",
    "    while not(done):\n",
    "        print(\"current_patch: \", pid)\n",
    "        out3 = online_datagen(pid, K_mm, sz=300, viz=False, nrep=40)\n",
    "        if len(out3[0])>=Nmax:\n",
    "            p_gt = (out3[0][0:Nmax,:,:,:], out3[2][0:Nmax])\n",
    "            if len(p_gt[0]>1):\n",
    "                out_preds = training_opt(p_gt, optimz, criterion1, mod2, iters=5)\n",
    "            if out_preds is not None:\n",
    "                mme_pixels = None  \n",
    "                if len(out_preds[0][0])>=1:\n",
    "                    uv_pds.append(np.vstack(out_preds[0][0])) \n",
    "                    uv_gts.append(np.vstack(out_preds[0][1]))\n",
    "                    a_uv_pd = np.vstack(uv_pds)\n",
    "                    a_uv_gt = np.vstack(uv_gts)\n",
    "                    mme_pixels = np.median(np.abs(a_uv_gt-a_uv_pd))\n",
    "                    print(\"mean error: \", mme_pixels, ' pixels')\n",
    "                    \n",
    "                comb_loss.append(out_preds[1])\n",
    "                if epoch%20==0:\n",
    "                    vizb = True\n",
    "                    pp = True\n",
    "                else:\n",
    "                    vizb = False\n",
    "\n",
    "                if epoch%20==0:\n",
    "                    out_4 =  plot_progress_opt(a_uv_pd, a_uv_gt, comb_loss)\n",
    "\n",
    "                if mme_pixels is not None:\n",
    "                    if mme_pixels<=prev_error:\n",
    "                        torch.save(mod2.state_dict(), opt_models+'/raft_match_comb_' +str(pid)+ '.pth')\n",
    "                        prev_error = mme_pixels\n",
    "                    if (epoch>=Nepoch) and (mme_pixels<=0.3):\n",
    "                        done = True\n",
    "                    elif epoch>=Ne_max:\n",
    "                        done = True\n",
    "            epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3d Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.path import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def hog_similarity(img1, img2):\n",
    "    img1 = np.array(img1).astype(np.uint8)\n",
    "    img2 = np.array(img2).astype(np.uint8)\n",
    "    feat1 = hog(img1, pixels_per_cell=(8, 8), cells_per_block=(2, 2),\n",
    "                orientations=9, block_norm='L2-Hys', feature_vector=True)\n",
    "    feat2 = hog(img2, pixels_per_cell=(8, 8), cells_per_block=(2, 2),\n",
    "                orientations=9, block_norm='L2-Hys', feature_vector=True)\n",
    "    sim = cosine_similarity([feat1], [feat2])[0, 0]\n",
    "    sim = (sim + 1) / 2.0\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_uv(pred_ptz_1_2, uvc_1, H12_c, polygon_path):\n",
    "    p_duvc_1_2 = pred_ptz_1_2.squeeze(0).permute(1, 2, 0).cpu().numpy() \n",
    "    u_ind, v_ind = uvc_1[:,0].astype(np.int16), uvc_1[:,1].astype(np.int16)\n",
    "    p_uv2_0 = uvc_1 + p_duvc_1_2[v_ind,u_ind,:]\n",
    "    p_uv2_ = p_uv2_0.T\n",
    "    onsx = np.ones_like(p_uv2_[0,:])\n",
    "    p_uv2_ = np.vstack((p_uv2_,onsx))\n",
    "    p_uv2_ = H12_c@p_uv2_\n",
    "    p_uv2_ = p_uv2_[0:2,:] / (p_uv2_[2:,:] + 1e-12)\n",
    "    p_uv2_ = p_uv2_.T\n",
    "    p_uv2_n = np.array(p_uv2_)\n",
    "    msk = polygon_path.contains_points(p_uv2_n)\n",
    "    return p_uv2_, msk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "mod11 = copy.deepcopy(mod2).eval()\n",
    "mod12 = copy.deepcopy(mod2).eval()\n",
    "mod21 = copy.deepcopy(mod1).eval()\n",
    "mod22 = copy.deepcopy(mod1).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_matrix(UV, Kmm, tm, Rm):\n",
    "    Q = Kmm @ Rm @ tm.reshape(-1,1)\n",
    "    D = Kmm @ Rm\n",
    "    B = Q[0:2,:] - Q[-1,:] * UV\n",
    "    A = D[0:2,:] - D[-1,:] * UV\n",
    "    return A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uv_temp(Km,t2,R2_,xyz_v=None,bxm=None,nsamp=50000):\n",
    "    if (xyz_v is None) and (bxm is not None):\n",
    "        x_m = np.random.uniform(bxm[:,0].min(),bxm[:,0].max(),nsamp)\n",
    "        y_m = np.random.uniform(bxm[:,1].min(),bxm[:,1].max(),nsamp)\n",
    "        z_m = np.random.uniform(bxm[:,2].min(),bxm[:,2].max(),nsamp)\n",
    "        xyz_v = np.vstack((x_m,y_m,z_m))\n",
    "    zuv2 = Km @ R2_ @ (xyz_v - t2)\n",
    "    uv2 = zuv2[0:2,:]/zuv2[2:,:]\n",
    "    return uv2.T, xyz_v.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ptz_uv(uv_, hhn=480,wwn=640):\n",
    "    mskk = np.zeros((hhn,wwn),dtype=np.uint8)\n",
    "    pts = np.array(uv_).T.astype(np.int32)\n",
    "    cv2.fillPoly(mskk, pts[np.newaxis,:,:], 1)\n",
    "    vv_1n, uu_1n = np.where(mskk > 0)\n",
    "    uv_op = np.vstack((uu_1n, vv_1n)).T\n",
    "    return uv_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dmin(H12,u1p,u2g):\n",
    "    ons = np.ones_like(u1p[:,0]).reshape(-1,1)\n",
    "    u1p = np.hstack((u1p,ons)).T\n",
    "    u1p_ = H12 @ u1p\n",
    "    u1p_ = u1p_[0:2,:]/u1p_[2:,:]\n",
    "    dd = np.median(np.abs(u1p_.T - u2g))\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calib_img(modd, modd2, im_indx, Kmm, iters=1, sz=300, n_avg=5, viz=False, init_calib=False, idd=None):\n",
    "    ###This function is used for pixel-wise association and calibration of images without intrinsics according to Algorithm2\n",
    "    clear_output(wait=True)\n",
    "    print(\"im_indx: \", im_indx)\n",
    "    with torch.no_grad():\n",
    "        idx = nimg_0.index(im_indx[0])\n",
    "        idx2 = nimg_0.index(im_indx[1])\n",
    "        img1 = IMGS[idx]\n",
    "        img2 = IMGS[idx2]\n",
    "        imgp1, imgp2 = np.array(img1).astype(np.uint8), np.array(img2).astype(np.uint8)\n",
    "        imgp1_r, imgp2_r = imgp1.astype(np.uint8), imgp2.astype(np.uint8)\n",
    "\n",
    "        img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY).astype(np.uint8)\n",
    "        img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY).astype(np.uint8)\n",
    "        hh,ww = img1.shape[0:2]\n",
    "\n",
    "        t1 = np.array(TRNS[idx]).reshape(-1,1)\n",
    "        q1 = np.array(QUTS[idx]).tolist()\n",
    "        R1_ = np.array(R.from_quat([q1[1],q1[2],q1[3],q1[0]]).as_matrix())\n",
    "        t2 = np.array(TRNS[idx2]).reshape(-1,1)\n",
    "        q2 = np.array(QUTS[idx2]).tolist()\n",
    "        R2_ = np.array(R.from_quat([q2[1],q2[2],q2[3],q2[0]]).as_matrix())\n",
    "        a_uv1, a_uv2, a_uv1_w = [], [], []\n",
    "        a_xyz = []\n",
    "        bx_smb1 = BXMs[idx]\n",
    "        bx_smb2 = BXMs[idx2]\n",
    "        ptz_img1, ptz_img2 = [], []\n",
    "        \n",
    "        for kk, (ptz1, ptz2) in enumerate(zip(bx_smb1,bx_smb2)):\n",
    "            if (ptz1 is not None) and (ptz2 is not None):\n",
    "\n",
    "                #TODO\n",
    "                # Sample 3D points given bounds of the BIM to calibrate img1 - given img2 parameters\n",
    "                uv2_all, XYZ_ = uv_temp(Kmm, t2, R2_, bxm=bx_smb[kk])\n",
    "                uv_ = ptz1.T\n",
    "                uv_2 = ptz2.T\n",
    "                \n",
    "                polygon_path1 = Path(uv_.T.astype(np.int16))\n",
    "                polygon_path2 = Path(uv_2.T.astype(np.int16))\n",
    "                \n",
    "                img1_0 = comp_mskk(img1, uv_.astype(np.int16))\n",
    "                img2_0 = comp_mskk(img2, uv_2.astype(np.int16))\n",
    "\n",
    "                imgp1_r = comp_mskk(imgp1, uv_.astype(np.int16))\n",
    "                imgp2_r = comp_mskk(imgp2, uv_2.astype(np.int16))\n",
    "                image1 = torch.tensor(imgp1_r).permute(2, 0, 1).unsqueeze(0).cuda()\n",
    "                image2 = torch.tensor(imgp2_r).permute(2, 0, 1).unsqueeze(0).cuda()\n",
    "                ptz_img1.append(img1_0), ptz_img2.append(img2_0)\n",
    "                \n",
    "                uvc_1 = ptz_uv(uv_)\n",
    "                if init_calib: ## Calibrate img1 - given img2 parameters\n",
    "                    flg2 = (uv2_all[:,0]>=0) * (uv2_all[:,0]<640) * (uv2_all[:,1]>=0) * (uv2_all[:,1]<480)\n",
    "                    uvc_2_kpt = uv2_all[flg2,:]\n",
    "                    XYZ_ptz = XYZ_[flg2,:]\n",
    "                else:\n",
    "                    uvc_2_kpt = ptz_uv(uv_2)\n",
    "\n",
    "                uvc_1_t = torch.tensor(uvc_1).float()\n",
    "                uvc_2_t = torch.tensor(uvc_2_kpt).float()\n",
    "                img1_00, img2_00 = np.array(img1_0).astype(np.uint8), np.array(img2_0).astype(np.uint8)\n",
    "                img_tsr10 = F.interpolate(torch.tensor(img1_00/255.0).unsqueeze(0).unsqueeze(0), size=(sz,sz), mode='bilinear', align_corners=False).squeeze(0).squeeze(0)\n",
    "                img_tsr20 = F.interpolate(torch.tensor(img2_00/255.0).unsqueeze(0).unsqueeze(0), size=(sz,sz), mode='bilinear', align_corners=False).squeeze(0).squeeze(0)\n",
    "                K1 = np.array(Kmm)\n",
    "                H12_c, H21_c = np.eye(3), np.eye(3)\n",
    "                ref_uv2 = []\n",
    "                ref_uv1 = []\n",
    "                mtx1, mtx2, msk1, msk2 = [], [], [], []\n",
    "                for j in range(iters): \n",
    "                    img_tsr1 = F.interpolate(torch.tensor(img1_0/255.0).unsqueeze(0).unsqueeze(0), size=(sz,sz), mode='bilinear', align_corners=False).squeeze(0).squeeze(0)\n",
    "                    img_tsr2 = F.interpolate(torch.tensor(img2_0/255.0).unsqueeze(0).unsqueeze(0), size=(sz,sz), mode='bilinear', align_corners=False).squeeze(0).squeeze(0)\n",
    "                    comb_tsr1 = torch.stack([img_tsr10, img_tsr2],0).float()\n",
    "                    comb_tsr2 = torch.stack([img_tsr20, img_tsr1],0).float()\n",
    "\n",
    "                    pred_homo1 = modd2[kk](comb_tsr1.unsqueeze(0).to(device))\n",
    "                    pred_homo2 = modd2[kk](comb_tsr2.unsqueeze(0).to(device))\n",
    "                    \n",
    "                    fscale1, cscale1, quat1 = pred_homo1\n",
    "                    fs1, cs1  = fscale1.cpu().numpy(), cscale1.cpu().numpy()\n",
    "                    sh = np.zeros((2,2))\n",
    "                    qtn1 = quat1/quat1.norm(p=2,dim=1,keepdim=True)\n",
    "                    qtn1 = qtn1.cpu().numpy()\n",
    "                    \n",
    "                    fscale2, cscale2, quat2 = pred_homo2\n",
    "                    fs2, cs2  = fscale2.cpu().numpy(), cscale2.cpu().numpy()\n",
    "                    qtn2 = quat2/quat2.norm(p=2,dim=1,keepdim=True)\n",
    "                    qtn2 = qtn2.cpu().numpy()\n",
    "\n",
    "                    K12 = update_k(fs1[0,:], cs1[0,:], K1)\n",
    "                    K21 = update_k(fs2[0,:], cs2[0,:], K1) \n",
    "                    R12 = calRfq(qtn1[0,:].flatten().tolist())\n",
    "                    R21 = calRfq(qtn2[0,:].flatten().tolist()) \n",
    "                    \n",
    "                    H12 = K12 @ R12 @ np.linalg.inv(K1)\n",
    "                    H21 = K21 @ R21 @ np.linalg.inv(K1)\n",
    "                    H12_c = np.array(H12 @ H12_c)\n",
    "                    H21_c = np.array(H21 @ H21_c)\n",
    "\n",
    "                    img2_0 = homo_unwarp(img2_00, H12_c)\n",
    "                    img1_0 = homo_unwarp(img1_00, H21_c)\n",
    "                    \n",
    "                    img2_0r = homo_unwarp(imgp2_r, H12_c)\n",
    "                    img1_0r = homo_unwarp(imgp1_r, H21_c)\n",
    "\n",
    "                    image1n = torch.tensor(img1_0r).permute(2, 0, 1).unsqueeze(0).cuda()\n",
    "                    image2n = torch.tensor(img2_0r).permute(2, 0, 1).unsqueeze(0).cuda()\n",
    "                    _, pred_ptz_1_2 = modd[kk](image1, image2n, iters=12, test_mode=True)\n",
    "                    _, pred_ptz_2_1 = modd[kk](image2, image1n, iters=12, test_mode=True)\n",
    "\n",
    "                    p_uv1_0, msk10 = update_uv(pred_ptz_2_1, uvc_2_kpt, H21_c, polygon_path2)\n",
    "                    p_uv2_0, msk20 = update_uv(pred_ptz_1_2, uvc_1, H12_c, polygon_path1)\n",
    "                    \n",
    "                    # TODO\n",
    "                    # Geometric metric can be used after image pairs are calibrated\n",
    "                    # d10_ = get_dmin(H12_c,uv1_all,uv2_all)\n",
    "                    # d12 = get_dmin(np.linalg.inv(H21_c),uv1_all,uv2_all)\n",
    "                    # d20_ = get_dmin(H21_c,uv2_all,uv1_all)\n",
    "                    # d21 = get_dmin(np.linalg.inv(H12_c),uv2_all,uv1_all)\n",
    "                    # d10 = min([d10_, d12])\n",
    "                    # d20 = min([d20_, d21])\n",
    "\n",
    "                    #Photometric metric - applies irrespective of calibration\n",
    "                    mtrc10 = hog_similarity(img2_00, img1_0)\n",
    "                    mtrc20 = hog_similarity(img1_00, img2_0)\n",
    "                    mtx1.append(mtrc10) #mtx1.append(d10)\n",
    "                    msk1.append(msk10)\n",
    "                    ref_uv1.append(p_uv1_0)\n",
    "                    mtx2.append(mtrc20) #mtx2.append(d20)\n",
    "                    msk2.append(msk20)\n",
    "                    ref_uv2.append(p_uv2_0)\n",
    "                    \n",
    "        \n",
    "                b_ind1 = np.argmax(mtx1) #np.argmin(mtx1) #\n",
    "                b_ind2 = np.argmax(mtx2) #np.argmin(mtx2) #\n",
    "                ref_uv1_arr_m = ref_uv1[b_ind1]\n",
    "                ref_uv2_arr_m = ref_uv2[b_ind2]\n",
    "                ff1 = (ref_uv1_arr_m[:,0]>=0) * (ref_uv1_arr_m[:,0]<ww) * (ref_uv1_arr_m[:,1]>=0) * (ref_uv1_arr_m[:,1]<hh)\n",
    "                ff2 = (ref_uv2_arr_m[:,0]>=0) * (ref_uv2_arr_m[:,0]<ww) * (ref_uv2_arr_m[:,1]>=0) * (ref_uv2_arr_m[:,1]<hh)\n",
    "                if init_calib:\n",
    "                    a_uv1.append(ref_uv1_arr_m[ff1,:]) \n",
    "                    a_uv2.append(uvc_2_kpt[ff1,:]) \n",
    "                    a_xyz.append(XYZ_ptz[ff1,:]) \n",
    "                else:\n",
    "                    a_uv1.append((ref_uv1_arr_m[ff1,:].astype(np.int16),uvc_1[ff2,:]))\n",
    "                    a_uv2.append((ref_uv2_arr_m[ff2,:].astype(np.int16),uvc_2_kpt[ff1,:]))\n",
    "                \n",
    "            else:\n",
    "                if not init_calib:\n",
    "                    a_uv1.append(None)\n",
    "                    a_uv2.append(None)\n",
    "                    ptz_img1.append(None), ptz_img2.append(None)\n",
    "        \n",
    "        if len(a_uv1)>=1 and init_calib:\n",
    "            ## Running PnP to calibrate img1\n",
    "            AXYZ = np.vstack(a_xyz)\n",
    "            AUV1 = np.vstack(a_uv1)\n",
    "            AUV2 = np.vstack(a_uv2)\n",
    "            if viz:\n",
    "                h1, w1 = imgp1.shape[:2]; h2, w2 = imgp2.shape[:2]\n",
    "                imgc = np.hstack((img1_0, img2_00))\n",
    "                vis = np.zeros((max(h1,h2), w1+w2, 3), dtype=np.uint8)\n",
    "                vis[:h1, :w1, :] = np.array(imgp1).astype(np.uint8)\n",
    "                vis[:h2, w1:w1+w2, :] = np.array(imgp2).astype(np.uint8)\n",
    "                vis2 = np.array(vis).astype(np.uint8)\n",
    "                \n",
    "                pts1 = np.array(AUV1)\n",
    "                pts2 = np.array(AUV2)\n",
    "                nnmax = 50\n",
    "                nnid = random.sample(range(len(pts1)),nnmax)\n",
    "                pts1_ = pts1[nnid,:]\n",
    "                pts2_ = pts2[nnid,:]\n",
    "                color = (0,255,0)\n",
    "                for (x1,y1), (x2,y2) in zip(pts1_, pts2_):\n",
    "                    pt1 = (int(x1), int(y1))\n",
    "                    pt2 = (int(x2)+w1, int(y2))\n",
    "                    cv2.line(vis, pt1, pt2, color, 1, cv2.LINE_AA)\n",
    "                    cv2.circle(vis, pt1, 4, color, -1)\n",
    "                    cv2.circle(vis, pt2, 4, color, -1)\n",
    "                plt.figure(figsize=(12,12))\n",
    "                plt.imshow(vis) \n",
    "                \n",
    "                ## Evolution of HOG similarity scores\n",
    "                plt.figure(figsize=(7,3))\n",
    "                plt.plot(mtx1, '--*',label='metrics_1_2')\n",
    "                plt.plot(mtx2,'--*',label='metrics_2_1')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "                plt.close()\n",
    "            \n",
    "            \n",
    "            print(\"AXYZ: \", AXYZ.shape)\n",
    "            print(\"AUV1: \", AUV1.shape)\n",
    "            dist_coeffs = np.zeros(5)\n",
    "            if len(AUV1>=8):\n",
    "                success, rvec, tvec, inliers = cv2.solvePnPRansac(\n",
    "                    AXYZ.astype(np.float32), AUV1.astype(np.float32), Kmm, dist_coeffs,\n",
    "                    reprojectionError=20.0,\n",
    "                    confidence=0.99,\n",
    "                    flags=cv2.SOLVEPNP_ITERATIVE\n",
    "                )\n",
    "                if success:\n",
    "                    Rm, _ = cv2.Rodrigues(rvec)\n",
    "                    trans = (-Rm.T@tvec).flatten()\n",
    "                    TRNS[idx] = np.array(trans).flatten()\n",
    "                    R_idx = np.array(Rm)\n",
    "                    q_idx = np.array(R.from_matrix(R_idx).as_quat()).tolist()\n",
    "                    QUTS[idx] = [q_idx[-1],q_idx[0],q_idx[1],q_idx[2]]\n",
    "        else:\n",
    "            return a_uv1, a_uv2, ptz_img1, ptz_img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "nimg_0s = nimg_0[:]\n",
    "nimg_gs = list(itertools.combinations(nimg_0s, 2)) ## Form pairs of images in the collection \n",
    "idx1, idx2 = 0, 5 # Example to calibrate nimg_0s[0], given parematers of nimg_0s[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods1 = []\n",
    "mods2 = []\n",
    "for pk in range(n_patches):\n",
    "    mod12.load_state_dict(torch.load(opt_models+'/raft_match_comb_' +str(pk)+ '.pth'))\n",
    "    mod22.load_state_dict(torch.load(homo_models+'/homo_match_comb_' +str(pk)+ '.pth'))\n",
    "    mod1_pk = mod12.eval()\n",
    "    mod2_pk = mod22.eval()\n",
    "    mods1.append(mod1_pk)\n",
    "    mods2.append(mod2_pk)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_indx = [nimg_0[idx1],nimg_0[idx2]]\n",
    "out_c = calib_img(mods1, mods2, im_indx, K_mm, iters=10, sz=300, n_avg=50, viz=True, init_calib=True, idd=idx1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_opti_data(nimgs, nimgs_g, Kmm, iters, sz, n_avg, clib=False):\n",
    "    # build correspondences for 3D reconstruction\n",
    "    pts_3d = {}\n",
    "    idx_hist = [{} for _ in range(len(nimg_0))]  \n",
    "    next_pid = 0\n",
    "    for kk, pp in enumerate(nimgs_g):\n",
    "        idx1, idx2 = nimg_0.index(pp[0]), nimg_0.index(pp[1])\n",
    "        im_indx = pp[:]\n",
    "        out_c = calib_img(mods1, mods2, im_indx, Kmm, iters=iters, sz=sz, n_avg=n_avg, viz=False, init_calib=clib)\n",
    "        a_uv1, a_uv2, _, _ = out_c\n",
    "        img1_, img2_ = IMGS[idx1], IMGS[idx2]\n",
    "        a_img1_kpts, a_img2_kpts = [], []\n",
    "        for jj in range(n_patches): \n",
    "            if a_uv1[jj] is not None:\n",
    "                img1_kpts, img2_kpts = a_uv1[jj][1], a_uv2[jj][1]\n",
    "                img1_kpts_0, img2_kpts_0 = a_uv1[jj][0], a_uv2[jj][0]\n",
    "                img1_kpts = np.vstack((img1_kpts_0, img1_kpts))\n",
    "                img2_kpts = np.vstack((img2_kpts, img2_kpts_0))\n",
    "                a_img1_kpts.append(img1_kpts), a_img2_kpts.append(img2_kpts)\n",
    "        \n",
    "        if len(a_img1_kpts)>=1:\n",
    "            img1_kpts = np.vstack(a_img1_kpts)\n",
    "            img2_kpts = np.vstack(a_img2_kpts)\n",
    "            u1_idx = np.arange(img1_kpts.shape[0])\n",
    "            u2_idx = np.arange(img2_kpts.shape[0])\n",
    "\n",
    "            \n",
    "            for ii in range(len(u1_idx)):\n",
    "                uv1 = tuple(np.round(img1_kpts[u1_idx[ii], :].copy(), 6))\n",
    "                uv2 = tuple(np.round(img2_kpts[u2_idx[ii], :].copy(), 6))\n",
    "                cc1 = np.array(uv1).astype(np.int16)\n",
    "                cc2 = np.array(uv2).astype(np.int16)\n",
    "                if uv1 in idx_hist[idx1]:\n",
    "                    pid = idx_hist[idx1][uv1]\n",
    "                    if not any(img_idx == pp[1] for _, img_idx, _ in pts_3d[str(pid)]):\n",
    "                        pts_3d[str(pid)].append((np.array(uv2), nimgs.index(pp[1]), img2_[cc2[1],cc2[0],:]))\n",
    "                        idx_hist[idx2][uv2] = pid\n",
    "\n",
    "                elif uv2 in idx_hist[idx2]:\n",
    "                    pid = idx_hist[idx2][uv2]\n",
    "                    if not any(img_idx == pp[0] for _, img_idx, _ in pts_3d[str(pid)]):\n",
    "                        pts_3d[str(pid)].append((np.array(uv1), nimgs.index(pp[0]), img1_[cc1[1],cc1[0],:]))\n",
    "                        idx_hist[idx1][uv1] = pid\n",
    "\n",
    "                else:\n",
    "                    pid = next_pid\n",
    "                    pts_3d[str(pid)] = [\n",
    "                        (np.array(uv1), nimgs.index(pp[0]), img1_[cc1[1],cc1[0],:]),\n",
    "                        (np.array(uv2), nimgs.index(pp[1]), img2_[cc2[1],cc2[0],:])\n",
    "                    ]\n",
    "                    idx_hist[idx1][uv1] = pid\n",
    "                    idx_hist[idx2][uv2] = pid\n",
    "                    next_pid += 1\n",
    "    return pts_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "## At this state all images in the collection are calibrated\n",
    "TRNS_ = TRNS[:] \n",
    "QUTS_ = QUTS[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(pcd_dict, Kmm):\n",
    "    ## Traingulate 3D points\n",
    "    XYZpts = []\n",
    "    pcols = []\n",
    "    uv_vals = []\n",
    "    for key in pcd_dict.keys():\n",
    "        elems_to_xyz = pcd_dict[key]\n",
    "        uv_i = []\n",
    "        Am, Bm = [], []\n",
    "        acols = []\n",
    "        if len(elems_to_xyz)>=2:\n",
    "            try:\n",
    "                for elem in elems_to_xyz: \n",
    "                    uv, idx, color = elem\n",
    "                    uv_i.append((uv.flatten(), idx))\n",
    "                    acols.append(color)\n",
    "                    tm = np.array(TRNS_[idx])\n",
    "                    qm = QUTS_[idx]\n",
    "                    Rm = np.array(R.from_quat([qm[1],qm[2],qm[3],qm[0]]).as_matrix())\n",
    "                    am, bm = create_data_matrix(uv.reshape(-1,1), Kmm, tm, Rm)\n",
    "                    Am.append(am), Bm.append(bm)\n",
    "\n",
    "                Am, Bm = np.vstack(Am), np.vstack(Bm)\n",
    "                xyz_ls = np.linalg.inv(Am.T @ Am) @ Am.T @ Bm\n",
    "                XYZpts.append(xyz_ls.flatten())\n",
    "                pcols.append(np.median(acols,0).astype(np.uint8))\n",
    "                uv_vals.append(uv_i)\n",
    "            except:\n",
    "                pass\n",
    "        if len(XYZpts)>=850000:\n",
    "            break\n",
    "    return XYZpts, pcols, uv_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize 3D reconstruction\n",
    "def plot_pointcloud(XYZ, colors):\n",
    "    XYZ = np.asarray(XYZ)\n",
    "    colors = np.asarray(colors) / 255.0\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(\n",
    "        XYZ[:, 1], XYZ[:, 0], XYZ[:, 2],\n",
    "        c=colors, marker='o', s=0.9\n",
    "    )\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    ax.set_zlabel(\"Z\")\n",
    "    ax.set_xlim([-18,18.0])\n",
    "    ax.set_zlim([0.0,16.0])\n",
    "\n",
    "    max_range = np.array([\n",
    "        XYZ[:, 0].max() - XYZ[:, 0].min(),\n",
    "        XYZ[:, 1].max() - XYZ[:, 1].min(),\n",
    "        XYZ[:, 2].max() - XYZ[:, 2].min()\n",
    "    ]).max() / 2.0\n",
    "    # mid_x = (XYZ[:, 0].max() + XYZ[:, 0].min()) * 0.5\n",
    "    # mid_y = (XYZ[:, 1].max() + XYZ[:, 1].min()) * 0.5\n",
    "    # mid_z = (XYZ[:, 2].max() + XYZ[:, 2].min()) * 0.5\n",
    "    # ax.set_xlim(mid_x - max_range, mid_x + max_range)\n",
    "    # ax.set_ylim(mid_y - max_range, mid_y + max_range)\n",
    "    # ax.set_zlim(mid_z - max_range, mid_z + max_range)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out5 = calc_opti_data(nimg_0s, nimg_gs, K_mm, iters=10, sz=300, n_avg=50, clib=False)\n",
    "print('running 3D reconstruction')\n",
    "out6, pcols, uv_vals = reconstruct(out5, K_mm)\n",
    "XYZpts_p = np.vstack(out6)\n",
    "print(XYZpts_p.shape)\n",
    "plot_pointcloud(XYZpts_p, pcols)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
